{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txCP1_fZR1PW"
   },
   "source": [
    "# Pytorch\n",
    "\n",
    "Pytorch는 TensorFlow와 함께 Deep Learning에서 가장 널리 사용되는 framework입니다.\n",
    "\n",
    "초기에는 Torch라는 이름으로 Lua 언어 기반으로 만들어졌으나, 이후 python 기반으로 변경한 것이 Pytorch입니다. \n",
    "\n",
    "New York 대학교와 Facebook이 공동으로 만들었고, Deep Learning 연구자들 사이에서는 가장 대중적으로 널리 사용되는 framework입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63Q803K53JFb"
   },
   "source": [
    "## Pytorch Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXbSk7vvWlxn"
   },
   "source": [
    "### Pytorch import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8J0WMNj3QxxT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yYFv2sHXRyO"
   },
   "source": [
    "### Pytorch 맛보기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h_5pN_jhToDL"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9RdlFXVPXh7V"
   },
   "outputs": [],
   "source": [
    "## MNIST Data down 받기\n",
    "\n",
    "# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kTY_cIF1XpJd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 데이터로더를 생성합니다.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B31uL7ycX1re"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# 모델을 정의합니다.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),            \n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KsrTn40qX2KV"
   },
   "outputs": [],
   "source": [
    "# Loss 함수와 Optimizer 설정\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "36iRc41kYFj1"
   },
   "outputs": [],
   "source": [
    "# Training을 위한 함수\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u6_3yNPMYKO2"
   },
   "outputs": [],
   "source": [
    "# Test를 위한 함수\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CnhgYl0yYZJX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.309040  [    0/60000]\n",
      "loss: 0.443555  [ 6400/60000]\n",
      "loss: 0.333869  [12800/60000]\n",
      "loss: 0.422959  [19200/60000]\n",
      "loss: 0.261678  [25600/60000]\n",
      "loss: 0.335132  [32000/60000]\n",
      "loss: 0.156818  [38400/60000]\n",
      "loss: 0.340372  [44800/60000]\n",
      "loss: 0.264025  [51200/60000]\n",
      "loss: 0.330234  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.197345 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.132889  [    0/60000]\n",
      "loss: 0.207929  [ 6400/60000]\n",
      "loss: 0.118558  [12800/60000]\n",
      "loss: 0.179682  [19200/60000]\n",
      "loss: 0.160631  [25600/60000]\n",
      "loss: 0.247077  [32000/60000]\n",
      "loss: 0.061898  [38400/60000]\n",
      "loss: 0.234059  [44800/60000]\n",
      "loss: 0.167495  [51200/60000]\n",
      "loss: 0.221856  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.135589 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.086633  [    0/60000]\n",
      "loss: 0.132497  [ 6400/60000]\n",
      "loss: 0.079537  [12800/60000]\n",
      "loss: 0.086607  [19200/60000]\n",
      "loss: 0.098384  [25600/60000]\n",
      "loss: 0.159695  [32000/60000]\n",
      "loss: 0.043117  [38400/60000]\n",
      "loss: 0.181483  [44800/60000]\n",
      "loss: 0.136286  [51200/60000]\n",
      "loss: 0.179857  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.111970 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.057004  [    0/60000]\n",
      "loss: 0.097536  [ 6400/60000]\n",
      "loss: 0.069124  [12800/60000]\n",
      "loss: 0.053173  [19200/60000]\n",
      "loss: 0.072734  [25600/60000]\n",
      "loss: 0.123818  [32000/60000]\n",
      "loss: 0.033882  [38400/60000]\n",
      "loss: 0.134302  [44800/60000]\n",
      "loss: 0.114627  [51200/60000]\n",
      "loss: 0.130839  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.099691 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.038854  [    0/60000]\n",
      "loss: 0.064863  [ 6400/60000]\n",
      "loss: 0.056718  [12800/60000]\n",
      "loss: 0.033935  [19200/60000]\n",
      "loss: 0.056884  [25600/60000]\n",
      "loss: 0.098164  [32000/60000]\n",
      "loss: 0.023920  [38400/60000]\n",
      "loss: 0.100227  [44800/60000]\n",
      "loss: 0.097380  [51200/60000]\n",
      "loss: 0.082665  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.092430 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.030393  [    0/60000]\n",
      "loss: 0.039649  [ 6400/60000]\n",
      "loss: 0.049780  [12800/60000]\n",
      "loss: 0.034959  [19200/60000]\n",
      "loss: 0.039711  [25600/60000]\n",
      "loss: 0.082956  [32000/60000]\n",
      "loss: 0.017328  [38400/60000]\n",
      "loss: 0.071628  [44800/60000]\n",
      "loss: 0.084008  [51200/60000]\n",
      "loss: 0.050714  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.086057 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.030748  [    0/60000]\n",
      "loss: 0.025067  [ 6400/60000]\n",
      "loss: 0.042724  [12800/60000]\n",
      "loss: 0.027258  [19200/60000]\n",
      "loss: 0.027535  [25600/60000]\n",
      "loss: 0.062121  [32000/60000]\n",
      "loss: 0.013710  [38400/60000]\n",
      "loss: 0.049258  [44800/60000]\n",
      "loss: 0.079850  [51200/60000]\n",
      "loss: 0.034605  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.085843 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.027883  [    0/60000]\n",
      "loss: 0.017930  [ 6400/60000]\n",
      "loss: 0.036080  [12800/60000]\n",
      "loss: 0.023067  [19200/60000]\n",
      "loss: 0.022931  [25600/60000]\n",
      "loss: 0.049959  [32000/60000]\n",
      "loss: 0.010795  [38400/60000]\n",
      "loss: 0.035173  [44800/60000]\n",
      "loss: 0.071957  [51200/60000]\n",
      "loss: 0.021719  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.085173 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.028942  [    0/60000]\n",
      "loss: 0.010413  [ 6400/60000]\n",
      "loss: 0.029362  [12800/60000]\n",
      "loss: 0.022007  [19200/60000]\n",
      "loss: 0.019998  [25600/60000]\n",
      "loss: 0.035005  [32000/60000]\n",
      "loss: 0.006842  [38400/60000]\n",
      "loss: 0.024826  [44800/60000]\n",
      "loss: 0.064188  [51200/60000]\n",
      "loss: 0.019656  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082931 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.027969  [    0/60000]\n",
      "loss: 0.007799  [ 6400/60000]\n",
      "loss: 0.032436  [12800/60000]\n",
      "loss: 0.018926  [19200/60000]\n",
      "loss: 0.012597  [25600/60000]\n",
      "loss: 0.035888  [32000/60000]\n",
      "loss: 0.005794  [38400/60000]\n",
      "loss: 0.018321  [44800/60000]\n",
      "loss: 0.061107  [51200/60000]\n",
      "loss: 0.012750  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082635 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6cUrmf0Z4fo"
   },
   "source": [
    "내가 쓴 손글씨로 Test 해봅시다.\n",
    "\n",
    "Colab을 쓰는 경우에는 아래 cell을 실행하면 파일을 업로드할 수 있습니다.\n",
    "\n",
    "그림판과 같은 도구를 이용하여 손으로 숫자를 쓴 다음 파일로 저장하고 업로드 합니다.\n",
    "\n",
    "이 때 파일명은 image.png로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "59W62-QgYwMO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fc9ddafde9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0muploaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0X9zCSmaMCG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# image file의 경로 설정\n",
    "cur_dir = os.getcwd()\n",
    "img_path = os.path.join(cur_dir, 'image.png')\n",
    "# image file 읽기\n",
    "cur_img = Image.open(img_path)\n",
    "# 28x28로 resize\n",
    "cur_img = cur_img.resize((28, 28))\n",
    "image = np.asarray(cur_img)\n",
    "\n",
    "# color image일 경우 RGB 평균값으로 gray scale로 변경\n",
    "try:\n",
    "  image = np.mean(image, axis=2)\n",
    "except:\n",
    "  pass\n",
    "# upload한 image는 흰 배경에 검은 글씨로 되어 있으므로, MNIST data와 같이 검은 배경에 흰 글씨로 변경\n",
    "image = np.abs(255-image)\n",
    "# MNIST와 동일하게 data preprocessing(255로 나눠줌)\n",
    "image = image.astype(np.float32)/255.\n",
    "# 화면에 출력하여 확인\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Kzj2yru_aW_C"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3227d04e253c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model이 예측한 값은 {} 입니다.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "image = torch.as_tensor(image).to(device).reshape(1,1,28,28)\n",
    "model.eval()\n",
    "predict = model(image)\n",
    "print(\"Model이 예측한 값은 {} 입니다.\".format(predict.argmax(1).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij2YufhijT8r"
   },
   "source": [
    "### Tensor\n",
    "\n",
    "텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력(input)과 출력(output), 그리고 모델의 매개변수들을 부호화(encode)합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kZX5qD2yas4W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# list로부터 직접 tensor 생성하기 \n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gyl8vKttt7jq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# numpy array로부터 tensor 생성하기\n",
    "np_array = np.array(data)\n",
    "x_np_1 = torch.tensor(np_array)\n",
    "print(x_np_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NjcTTEfPuEBk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x_np_2 = torch.as_tensor(np_array)\n",
    "print(x_np_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GrhahgRwuK18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x_np_3 = torch.from_numpy(np_array)\n",
    "print(x_np_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EP7-VKXZuPSk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_1[0,0] = 5\n",
    "print(x_np_1)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "asd0tYpyuVYk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[6 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_2[0,0] = 6\n",
    "print(x_np_2)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dhlhRbXZuakk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[7 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_3[0,0] = 7\n",
    "print(x_np_3)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sDjZtvbl1t55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_again = x_np_1.numpy()\n",
    "print(np_again, type(np_again))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UAJXi6dLukuE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2]])\n",
      "tensor([[4.2465e-08, 4.2249e-05, 4.2187e-08],\n",
      "        [1.7664e-04, 5.4688e-05, 5.4216e-05]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,3)\n",
    "b = torch.zeros(2,3)\n",
    "c = torch.full((2,3), 2)\n",
    "d = torch.empty(2,3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2hy9UD_9wt8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.zeros_like(c)\n",
    "f = torch.ones_like(c)\n",
    "g = torch.full_like(c, 3)\n",
    "h = torch.empty_like(c)\n",
    "print(e)\n",
    "print(f)\n",
    "print(g)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e_sa93IYw9bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.eye(3)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KbFJzWSsxGJv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "j = torch.arange(10)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FxgtCvqru4ID"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1352, 0.6312],\n",
      "        [0.5160, 0.6777]])\n",
      "tensor([[-1.0761, -0.5403],\n",
      "        [ 1.3285,  0.1425]])\n"
     ]
    }
   ],
   "source": [
    "k = torch.rand(2,2)\n",
    "l = torch.randn(2,2)\n",
    "print(k)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybi6d3J6xcg_"
   },
   "source": [
    "#### Tensor의 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3HUKWFr6vV0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OqBxAjy_yrEA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([4, 3])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 속성 변경\n",
    "tensor = tensor.reshape(4,3)\n",
    "tensor = tensor.int()\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiC7ViT1yMyP"
   },
   "source": [
    "### Indexing과 Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e_mwMvjryMGR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 13).reshape(3, 4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uM0X_yiTxVS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# indexing\n",
    "print(a[1])\n",
    "print(a[0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hne1WelrxV-c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 7, 8]])\n",
      "tensor([[3, 4],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# slicing\n",
    "print(a[1:-1])\n",
    "print(a[:2, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LDBFZ7GzyB5"
   },
   "source": [
    "### Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yPHd8DjiynMM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]]) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(16).reshape(2,2,4)\n",
    "print(a, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ihgjJ7z1z45s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  4],\n",
      "         [ 1,  5],\n",
      "         [ 2,  6],\n",
      "         [ 3,  7]],\n",
      "\n",
      "        [[ 8, 12],\n",
      "         [ 9, 13],\n",
      "         [10, 14],\n",
      "         [11, 15]]]) torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "b = a.transpose(1, 2)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "17QBnkcUz_j1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  4],\n",
      "         [ 8, 12]],\n",
      "\n",
      "        [[ 1,  5],\n",
      "         [ 9, 13]],\n",
      "\n",
      "        [[ 2,  6],\n",
      "         [10, 14]],\n",
      "\n",
      "        [[ 3,  7],\n",
      "         [11, 15]]]) torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "c = a.permute((2, 0, 1))\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs8pjQEk0Xq5"
   },
   "source": [
    "### Tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "gAzq1rhW0ELt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2], [3,4]], dtype=torch.float32)\n",
    "y = torch.tensor([[5,6], [7,8]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7hewUZsy0mBW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "==============================\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x @ y)\n",
    "print('='*30)\n",
    "print(torch.add(x, y))\n",
    "print(torch.subtract(x, y))\n",
    "print(torch.multiply(x, y))\n",
    "print(torch.divide(x, y))\n",
    "print(torch.matmul(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HyQBtTjY1b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# in-place 연산\n",
    "print(x.add(y))\n",
    "print(x)\n",
    "print(x.add_(y))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PryILS5s09cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.arange(1, 11).reshape(2, 5)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yH3_rGlI1KlV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  9, 11, 13, 15]) torch.Size([5])\n",
      "tensor([15, 40]) torch.Size([2])\n",
      "tensor([15, 40]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "sum1 = torch.sum(z, axis=0)\n",
    "sum2 = torch.sum(z, axis=1)\n",
    "sum3 = torch.sum(z, axis=-1)\n",
    "print(sum1, sum1.shape)\n",
    "print(sum2, sum2.shape)\n",
    "print(sum3, sum3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BLH0MpQL1OlN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([4, 6])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([4, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(4, 6)\n",
    "b = a.clone().detach()\n",
    "print(a, a.shape)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "TmqvBX6w2IFu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23],\n",
      "        [ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat([a, b], axis=0)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "uoUGG-PU2y0O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23, 18, 19, 20, 21, 22, 23]]) torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat([a, b], axis=-1)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "c36QSNnY264-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11],\n",
      "         [12, 13, 14, 15, 16, 17],\n",
      "         [18, 19, 20, 21, 22, 23]],\n",
      "\n",
      "        [[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11],\n",
      "         [12, 13, 14, 15, 16, 17],\n",
      "         [18, 19, 20, 21, 22, 23]]]) torch.Size([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack([a, b], axis=0)\n",
    "print(d, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9o3GPwPM2-Me"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  0],\n",
      "         [ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5]],\n",
      "\n",
      "        [[ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11]],\n",
      "\n",
      "        [[12, 12],\n",
      "         [13, 13],\n",
      "         [14, 14],\n",
      "         [15, 15],\n",
      "         [16, 16],\n",
      "         [17, 17]],\n",
      "\n",
      "        [[18, 18],\n",
      "         [19, 19],\n",
      "         [20, 20],\n",
      "         [21, 21],\n",
      "         [22, 22],\n",
      "         [23, 23]]]) torch.Size([4, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack([a, b], axis=-1)\n",
    "print(d, d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HEaHRVw3Noy"
   },
   "source": [
    "## Dataset / Dataloader\n",
    "\n",
    "Data를 처리하여 model에 공급하는 방법으로 Pytorch에서는 Dataset과 DataLoader를 제공합니다.\n",
    "\n",
    "Dataset은 data와 label을 저장하고, DataLoader는 Dataset을 model에 공급할 수 있도록 iterable 객체로 감싸줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJBl5rK132CD"
   },
   "source": [
    "### FasionMNIST data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zH1pEvzUGv-7"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pq87kH2t2_8W"
   },
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcBC4NAm3_Rr"
   },
   "source": [
    "### 데이터 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4sJcQTr36nv"
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNeINRxdHYb7"
   },
   "source": [
    "### DataLoader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOiMGBbgGpwb"
   },
   "outputs": [],
   "source": [
    "# DataLoader 만들기\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDlvthoZGpzU"
   },
   "outputs": [],
   "source": [
    "# DataLoader를 통해 반복하기(iterate)\n",
    "# 이미지와 정답(label)을 표시합니다.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3LsVobUHass"
   },
   "source": [
    "### Custom Dataset, Data Loader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZHsPRBc4Ddn"
   },
   "outputs": [],
   "source": [
    "# 간단한 Custom Dataset/Transform/DataLoader 만들기\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, np_data, transform=None):\n",
    "    self.data = np_data\n",
    "    self.transform = transform\n",
    "    self.len = np_data.shape[0]\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "  def __getitem__(self, idx):    \n",
    "    sample = self.data[idx]\n",
    "    if self.transform:\n",
    "      sample = self.transform(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-0Eztv9GwSR"
   },
   "outputs": [],
   "source": [
    "def square(sample):\n",
    "  return sample**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ahheTBjGJE3"
   },
   "outputs": [],
   "source": [
    "trans = tr.Compose([square])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMGw6_wTDkP6"
   },
   "outputs": [],
   "source": [
    "np_data = np.arange(10)\n",
    "\n",
    "custom_dataset = CustomDataset(np_data, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjfLJqfdD1CS"
   },
   "outputs": [],
   "source": [
    "custom_dataloader = DataLoader(custom_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OijYYFTHD_Xy"
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "  for data in custom_dataloader:\n",
    "    print(data)\n",
    "  print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBIhASxPHgDb"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1CP4rACEJxd"
   },
   "outputs": [],
   "source": [
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVDCYr85H-5j"
   },
   "source": [
    "### Model class 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbtUxoUbH7Pe"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),            \n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eXhySj6IJaW"
   },
   "outputs": [],
   "source": [
    "# Model instance 생성, device 설정\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_k0QBI2INoW"
   },
   "outputs": [],
   "source": [
    "# 가상의 data 만들어서 예측해보기\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsIY58t0JB0V"
   },
   "source": [
    "## Training / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlkPl2JJJI9E"
   },
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LMgsDSoIYtG"
   },
   "outputs": [],
   "source": [
    "# 손실 함수를 초기화합니다.\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAlqtzkDJOZU"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7dELqElJNkW"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaYAnBUCJXe-"
   },
   "source": [
    "### Training / Validation(Test) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tje2CPpeJR5W"
   },
   "outputs": [],
   "source": [
    "# Training을 위한 함수\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# Test를 위한 함수\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTp_mTRKJxNe"
   },
   "outputs": [],
   "source": [
    "# 학습 진행하기\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSAxLgwNMJke"
   },
   "source": [
    "## Model 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAE2aT-LMPja"
   },
   "source": [
    "#### parameter만 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hD_9zmzLJ5aP"
   },
   "outputs": [],
   "source": [
    "# 학습된 model parameter 저장\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suOyvvDpMTeA"
   },
   "outputs": [],
   "source": [
    "# 새 Model instance 생성, device 설정\n",
    "model2 = NeuralNetwork().to(device)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vtLNWzdMmP_"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "model2.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epmWcHXlMsj3"
   },
   "outputs": [],
   "source": [
    "# 저장한 parameter 불러오기\n",
    "model2.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JBBYyaIM37v"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "model2.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjPKRMdtNFH_"
   },
   "source": [
    "### Model 전체를 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_ZjA5ehM78H"
   },
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oD0OjcyJNJ0_"
   },
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "model3 = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjZICUrCNM7X"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "model3.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2vRMsioNV3W"
   },
   "source": [
    "## Tensorboard 사용하여 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGnzohCJNR9Y"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BENziPMuNluP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./logs/pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVB7XWHwO9jH"
   },
   "outputs": [],
   "source": [
    "# 새 Model instance 생성, device 설정\n",
    "model4 = NeuralNetwork().to(device)\n",
    "print(model4)\n",
    "\n",
    "model4.eval()\n",
    "test_loop(test_dataloader, model4, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiTetkobNwUX"
   },
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "writer.add_graph(model4, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgGBmkZOONG4"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "        total_loss += loss / len(dataloader)\n",
    "    return total_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8o9uvecOZZ_"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1W2fyFMqPji4"
   },
   "outputs": [],
   "source": [
    "parameters = ['Weight1', 'Bias1', 'Weight2', 'Bias2']\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    writer.add_scalar('training loss', train_loss, t)\n",
    "    for param, name in zip(model.parameters(), parameters):\n",
    "        writer.add_histogram(name, param, t)\n",
    "    test_loss = test(test_dataloader, model, loss_fn)\n",
    "    writer.add_scalar('test_loss', test_loss, t)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeHuGnvaQAaQ"
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sk6SdayOQDRg"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir './logs/pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbX3qNzrQP_g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN8WVDw/ceKWvJVYF4ZDGQN",
   "collapsed_sections": [],
   "name": "Pytorch_Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

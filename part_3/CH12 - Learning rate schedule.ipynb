{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac38fc9",
   "metadata": {},
   "source": [
    "# Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad99c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d23bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.losses as losses\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    smooth = 0.\n",
    "    \n",
    "    # Flatten\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    \n",
    "    score = intersection / (union + smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.\n",
    "    \n",
    "    # Flatten\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    score = (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = 1.*losses.binary_crossentropy(y_true, y_pred) + 1.*dice_loss(y_true, y_pred)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6154a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, size, mode='train'):\n",
    "        if mode == 'train':\n",
    "            # Declare an augmentation pipeline\n",
    "            self.transform = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(\n",
    "                    p=0.5,\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=15\n",
    "                ),\n",
    "                A.CoarseDropout(\n",
    "                    p=0.5,\n",
    "                    max_holes=8,\n",
    "                    max_height=int(0.1 * size),\n",
    "                    max_width=int(0.1 * size)\n",
    "                ),\n",
    "                A.RandomBrightnessContrast(p=0.2),  \n",
    "            ])\n",
    "    def __call__(self, **kwargs):\n",
    "        if self.transform:\n",
    "            augmented = self.transform(**kwargs)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            return img, mask\n",
    "        \n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size,\n",
    "                 mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.fold = fold\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        invalid_filnames = [\n",
    "            'Egyptian_Mau_14',\n",
    "            'Egyptian_Mau_139',\n",
    "            'Egyptian_Mau_145',\n",
    "            'Egyptian_Mau_156',\n",
    "            'Egyptian_Mau_167',\n",
    "            'Egyptian_Mau_177',\n",
    "            'Egyptian_Mau_186',\n",
    "            'Egyptian_Mau_191',\n",
    "            'Abyssinian_5',\n",
    "            'Abyssinian_34',\n",
    "            'chihuahua_121',\n",
    "            'beagle_116'\n",
    "        ]\n",
    "        self.df = self.df[-self.df['file_name'].isin(invalid_filnames)]\n",
    "        self.transform = Augmentation(image_size, mode)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        final = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[start:final]\n",
    "        \n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        \n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['file_name']\n",
    "            \n",
    "            image = cv2.imread(f'data/images/{file_name}.jpg') # f는 f-string 문자열 포매팅\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            \n",
    "            mask = cv2.imread(f'data/annotations/trimaps/{file_name}.png',\n",
    "                              cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "            mask[mask != 1] = 0\n",
    "            \n",
    "            \n",
    "            if self.mode == 'train':\n",
    "#                 image = image.astype('uint8')\n",
    "                image, mask = self.transform(image=image, mask=mask)\n",
    "                \n",
    "            image = image.astype('float32')\n",
    "            image = image / 255.\n",
    "            mask = mask.astype('float32')\n",
    "#             label = int(r['id']) - 1\n",
    "            \n",
    "            batch_x.append(image)\n",
    "            batch_y.append(mask)\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "csv_path = 'data/kfolds.csv'\n",
    "train_generator = DataGenerator(\n",
    "    fold=1,\n",
    "    mode='train',\n",
    "    csv_path=csv_path,\n",
    "    batch_size=8,\n",
    "    image_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_generator = DataGenerator(\n",
    "    fold=1,\n",
    "    mode='val',\n",
    "    csv_path=csv_path,\n",
    "    batch_size=8,\n",
    "    image_size=128,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefa1711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4810892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b67d78e520>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decayed_learning_rate(step):\n",
    "    initial_learning_rate = 0.01\n",
    "    decay_rate = 0.96\n",
    "#     decay_steps = 735 * 10\n",
    "    decay_steps = 10\n",
    "    return initial_learning_rate * decay_rate ** (step / decay_steps)\n",
    "\n",
    "lrs = [decayed_learning_rate(i) for i in range(1, 735 * 10)]\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe977ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.96\n",
    ")\n",
    "optimizer = optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c330c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 64  1728        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d (SpatialDrop  (None, 128, 128, 64  0          ['batch_normalization[0][0]']    \n",
      " out2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 64  36864       ['spatial_dropout2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 128)  73728       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (SpatialDr  (None, 64, 64, 128)  0          ['batch_normalization_2[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 128)  147456      ['spatial_dropout2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 256)  294912      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (SpatialDr  (None, 32, 32, 256)  0          ['batch_normalization_4[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 256)  589824      ['spatial_dropout2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 512)  1179648     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_3 (SpatialDr  (None, 16, 16, 512)  0          ['batch_normalization_6[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 512)  2359296     ['spatial_dropout2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 1024)   4718592     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_4 (SpatialDr  (None, 8, 8, 1024)  0           ['batch_normalization_8[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 1024)   9437184     ['spatial_dropout2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 512)  2097664    ['batch_normalization_9[0][0]']  \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 512)  262656      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 512)  262656      ['conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 512)  0           ['conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 16, 16, 512)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 1)    513         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 1)    0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 512)  0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'multiply[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 512)  4718592     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 512)  2359296     ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 256)  524544     ['batch_normalization_11[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 256)  65792       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 32, 32, 256)  65792       ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 256)  0           ['conv2d_15[0][0]',              \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 32, 1)    257         ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 1)    0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 32, 32, 256)  0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 32, 256)  1179648     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 32, 256)  589824      ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 128)  131200     ['batch_normalization_13[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 64, 64, 128)  16512       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 64, 128)  16512       ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 64, 64, 128)  0           ['conv2d_20[0][0]',              \n",
      "                                                                  'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 64, 64, 1)    129         ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 1)    0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 64, 64, 128)  0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " concatenate_2 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 64, 64, 128)  294912      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 64, 128)  512        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 64, 64, 128)  147456      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 64, 128)  512        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 64  32832      ['batch_normalization_15[0][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 128, 128, 64  4160        ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 128, 128, 64  4160        ['conv2d_transpose_3[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 128, 128, 64  0           ['conv2d_25[0][0]',              \n",
      "                                )                                 'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 128, 128, 64  0           ['add_3[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 128, 128, 1)  65          ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 128, 128, 1)  0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 128, 128, 64  0           ['batch_normalization_1[0][0]',  \n",
      "                                )                                 'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 128, 128, 64  73728       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 128, 128, 64  256        ['conv2d_28[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 128, 128, 64  36864       ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 128, 64  256        ['conv2d_29[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 128, 128, 1)  65          ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,748,613\n",
      "Trainable params: 31,736,837\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/karolzak/keras-unet\n",
    "from keras_unet.models import custom_unet\n",
    "\n",
    "model = custom_unet(\n",
    "    input_shape=(128, 128, 3),\n",
    "    use_batch_norm=True,\n",
    "    upsample_mode='deconv',\n",
    "    dropout_type='spatial',\n",
    "    use_attention=True,\n",
    "    num_classes=1,\n",
    "    filters=64,\n",
    "    dropout=0.2,\n",
    "    num_layers=4,\n",
    "    output_activation='sigmoid')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=bce_dice_loss, metrics=[iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb30740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "735/735 [==============================] - 990s 1s/step - loss: 0.8850 - iou: 0.4157 - val_loss: 0.6975 - val_iou: 0.5070\n",
      "Epoch 2/10\n",
      "735/735 [==============================] - 653s 890ms/step - loss: 0.7311 - iou: 0.4893 - val_loss: 0.6591 - val_iou: 0.5284\n",
      "Epoch 3/10\n",
      "735/735 [==============================] - 636s 863ms/step - loss: 0.7185 - iou: 0.4972 - val_loss: 0.6582 - val_iou: 0.5300\n",
      "Epoch 4/10\n",
      "735/735 [==============================] - 635s 862ms/step - loss: 0.7157 - iou: 0.4986 - val_loss: 0.6586 - val_iou: 0.5305\n",
      "Epoch 5/10\n",
      "735/735 [==============================] - 632s 860ms/step - loss: 0.7150 - iou: 0.4983 - val_loss: 0.6581 - val_iou: 0.5307\n",
      "Epoch 6/10\n",
      "735/735 [==============================] - 631s 859ms/step - loss: 0.7187 - iou: 0.4969 - val_loss: 0.6569 - val_iou: 0.5310\n",
      "Epoch 7/10\n",
      "735/735 [==============================] - 634s 863ms/step - loss: 0.7184 - iou: 0.4971 - val_loss: 0.6576 - val_iou: 0.5310\n",
      "Epoch 8/10\n",
      "735/735 [==============================] - 631s 860ms/step - loss: 0.7159 - iou: 0.4982 - val_loss: 0.6582 - val_iou: 0.5304\n",
      "Epoch 9/10\n",
      "735/735 [==============================] - 631s 859ms/step - loss: 0.7166 - iou: 0.4981 - val_loss: 0.6585 - val_iou: 0.5306\n",
      "Epoch 10/10\n",
      "735/735 [==============================] - 632s 858ms/step - loss: 0.7170 - iou: 0.4975 - val_loss: 0.6614 - val_iou: 0.5289\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e132d95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-434fbba7791e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w/o scheduling'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'scheduling'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses[:10], label='w/o scheduling')\n",
    "plt.plot(history.history['loss'], label='scheduling')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"Train Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_ious[:10], label='w/o scheduling')\n",
    "plt.plot(history.history['iou'], label='scheduling')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('IoU')\n",
    "plt.title(\"Train IoU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875147bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(valid_losses[:10], label='w/o scheduling')\n",
    "plt.plot(history.history['val_loss'], label='scheduling')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"Valid Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valid_ious[:10], label='w/o scheduling')\n",
    "plt.plot(history.history['val_iou'], label='scheduling')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('IoU')\n",
    "plt.title(\"Valid IoU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6aaa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 문제 해결 (과적합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLNReluBlock(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(ConvLNReluBlock, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.ln = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.ln(x)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "# Define network architecture\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1_1 = ConvBNReluBlock(16, (3, 3))\n",
    "        self.conv1_2 = ConvBNReluBlock(16, (3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "\n",
    "        self.conv2_1 = ConvBNReluBlock(32, (3, 3))\n",
    "        self.conv2_2 = ConvBNReluBlock(32, (3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "\n",
    "        self.conv3_1 = ConvBNReluBlock(64, (3, 3))\n",
    "        self.conv3_2 = ConvBNReluBlock(64, (3, 3))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu',\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax',\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10 # 32x32x3 -> 10 class\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras API 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 51s 28ms/step - loss: 2.1546 - accuracy: 0.4414 - val_loss: 1.3968 - val_accuracy: 0.5305\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.2586 - accuracy: 0.5984 - val_loss: 1.1471 - val_accuracy: 0.6451\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.0899 - accuracy: 0.6588 - val_loss: 1.0602 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9881 - accuracy: 0.6950 - val_loss: 1.0096 - val_accuracy: 0.6911\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9183 - accuracy: 0.7186 - val_loss: 0.8986 - val_accuracy: 0.7291\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8666 - accuracy: 0.7383 - val_loss: 0.9211 - val_accuracy: 0.7230\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8249 - accuracy: 0.7520 - val_loss: 0.8783 - val_accuracy: 0.7344\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7872 - accuracy: 0.7676 - val_loss: 0.8822 - val_accuracy: 0.7322\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7491 - accuracy: 0.7791 - val_loss: 0.8241 - val_accuracy: 0.7563\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7208 - accuracy: 0.7897 - val_loss: 0.8228 - val_accuracy: 0.7594\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6965 - accuracy: 0.7993 - val_loss: 0.7734 - val_accuracy: 0.7724\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6728 - accuracy: 0.8068 - val_loss: 0.8339 - val_accuracy: 0.7539\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6543 - accuracy: 0.8117 - val_loss: 0.7610 - val_accuracy: 0.7795\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6297 - accuracy: 0.8226 - val_loss: 0.7706 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6146 - accuracy: 0.8260 - val_loss: 0.7963 - val_accuracy: 0.7681\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5944 - accuracy: 0.8336 - val_loss: 0.7943 - val_accuracy: 0.7707\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5741 - accuracy: 0.8406 - val_loss: 0.7357 - val_accuracy: 0.7895\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5673 - accuracy: 0.8448 - val_loss: 0.8185 - val_accuracy: 0.7683\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5528 - accuracy: 0.8484 - val_loss: 0.7783 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5363 - accuracy: 0.8541 - val_loss: 0.7889 - val_accuracy: 0.7741\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5199 - accuracy: 0.8615 - val_loss: 0.8234 - val_accuracy: 0.7714\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5068 - accuracy: 0.8663 - val_loss: 0.8046 - val_accuracy: 0.7693\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4977 - accuracy: 0.8672 - val_loss: 0.7701 - val_accuracy: 0.7862\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4862 - accuracy: 0.8715 - val_loss: 0.8331 - val_accuracy: 0.7767\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4748 - accuracy: 0.8779 - val_loss: 0.7974 - val_accuracy: 0.7783\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4605 - accuracy: 0.8825 - val_loss: 0.7907 - val_accuracy: 0.7840\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4513 - accuracy: 0.8852 - val_loss: 0.7903 - val_accuracy: 0.7830\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4412 - accuracy: 0.8893 - val_loss: 0.8464 - val_accuracy: 0.7747\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4327 - accuracy: 0.8928 - val_loss: 0.8473 - val_accuracy: 0.7742\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4214 - accuracy: 0.8954 - val_loss: 0.7959 - val_accuracy: 0.7886\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4134 - accuracy: 0.8998 - val_loss: 0.8478 - val_accuracy: 0.7752\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4017 - accuracy: 0.9038 - val_loss: 0.8925 - val_accuracy: 0.7639\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3952 - accuracy: 0.9052 - val_loss: 0.8234 - val_accuracy: 0.7832\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3842 - accuracy: 0.9094 - val_loss: 0.8376 - val_accuracy: 0.7810\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3826 - accuracy: 0.9118 - val_loss: 0.8874 - val_accuracy: 0.7736\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3684 - accuracy: 0.9162 - val_loss: 0.8383 - val_accuracy: 0.7808\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3692 - accuracy: 0.9157 - val_loss: 0.8521 - val_accuracy: 0.7768\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3606 - accuracy: 0.9191 - val_loss: 0.9303 - val_accuracy: 0.7654\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3562 - accuracy: 0.9203 - val_loss: 0.8982 - val_accuracy: 0.7729\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.3449 - accuracy: 0.9250 - val_loss: 0.8973 - val_accuracy: 0.7757\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3370 - accuracy: 0.9268 - val_loss: 0.9465 - val_accuracy: 0.7703\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3311 - accuracy: 0.9281 - val_loss: 0.8972 - val_accuracy: 0.7807\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3277 - accuracy: 0.9307 - val_loss: 0.9062 - val_accuracy: 0.7785\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3221 - accuracy: 0.9324 - val_loss: 0.9349 - val_accuracy: 0.7808\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3142 - accuracy: 0.9341 - val_loss: 0.9254 - val_accuracy: 0.7805\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3156 - accuracy: 0.9345 - val_loss: 0.9043 - val_accuracy: 0.7852\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3033 - accuracy: 0.9387 - val_loss: 0.9165 - val_accuracy: 0.7797\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3068 - accuracy: 0.9387 - val_loss: 0.9337 - val_accuracy: 0.7744\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.3005 - accuracy: 0.9390 - val_loss: 0.9457 - val_accuracy: 0.7827\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2940 - accuracy: 0.9421 - val_loss: 0.9668 - val_accuracy: 0.7744\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2898 - accuracy: 0.9439 - val_loss: 0.9996 - val_accuracy: 0.7713\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2923 - accuracy: 0.9422 - val_loss: 0.9714 - val_accuracy: 0.7734\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2804 - accuracy: 0.9469 - val_loss: 0.9813 - val_accuracy: 0.7762\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2798 - accuracy: 0.9470 - val_loss: 0.9739 - val_accuracy: 0.7760\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2762 - accuracy: 0.9480 - val_loss: 1.0153 - val_accuracy: 0.7689\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2741 - accuracy: 0.9499 - val_loss: 0.9800 - val_accuracy: 0.7749\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2761 - accuracy: 0.9476 - val_loss: 1.0073 - val_accuracy: 0.7773\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2650 - accuracy: 0.9516 - val_loss: 0.9822 - val_accuracy: 0.7713\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2622 - accuracy: 0.9543 - val_loss: 0.9921 - val_accuracy: 0.7763\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2631 - accuracy: 0.9528 - val_loss: 1.0386 - val_accuracy: 0.7644\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2543 - accuracy: 0.9556 - val_loss: 1.0495 - val_accuracy: 0.7676\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2606 - accuracy: 0.9539 - val_loss: 1.0781 - val_accuracy: 0.7693\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2561 - accuracy: 0.9544 - val_loss: 1.0145 - val_accuracy: 0.7821\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2513 - accuracy: 0.9560 - val_loss: 1.0654 - val_accuracy: 0.7680\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2503 - accuracy: 0.9564 - val_loss: 1.0414 - val_accuracy: 0.7589\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2499 - accuracy: 0.9560 - val_loss: 1.0534 - val_accuracy: 0.7749\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2368 - accuracy: 0.9609 - val_loss: 1.0239 - val_accuracy: 0.7807\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2466 - accuracy: 0.9567 - val_loss: 1.0054 - val_accuracy: 0.7754\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2438 - accuracy: 0.9578 - val_loss: 1.0102 - val_accuracy: 0.7792\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2340 - accuracy: 0.9621 - val_loss: 1.0431 - val_accuracy: 0.7766\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2395 - accuracy: 0.9601 - val_loss: 1.0185 - val_accuracy: 0.7792\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2331 - accuracy: 0.9625 - val_loss: 1.0595 - val_accuracy: 0.7761\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2315 - accuracy: 0.9618 - val_loss: 1.0728 - val_accuracy: 0.7649\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2322 - accuracy: 0.9620 - val_loss: 1.0303 - val_accuracy: 0.7761\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2303 - accuracy: 0.9629 - val_loss: 1.0863 - val_accuracy: 0.7692\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2257 - accuracy: 0.9631 - val_loss: 1.0161 - val_accuracy: 0.7766\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2149 - accuracy: 0.9671 - val_loss: 1.0899 - val_accuracy: 0.7722\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2235 - accuracy: 0.9650 - val_loss: 1.1170 - val_accuracy: 0.7798\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2225 - accuracy: 0.9646 - val_loss: 1.0658 - val_accuracy: 0.7738\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2135 - accuracy: 0.9671 - val_loss: 1.0926 - val_accuracy: 0.7677\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2221 - accuracy: 0.9652 - val_loss: 1.1523 - val_accuracy: 0.7646\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2114 - accuracy: 0.9679 - val_loss: 1.1099 - val_accuracy: 0.7755\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2200 - accuracy: 0.9644 - val_loss: 1.0691 - val_accuracy: 0.7758\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2128 - accuracy: 0.9670 - val_loss: 1.0917 - val_accuracy: 0.7824\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2082 - accuracy: 0.9691 - val_loss: 1.1236 - val_accuracy: 0.7694\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2106 - accuracy: 0.9676 - val_loss: 1.0591 - val_accuracy: 0.7742\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2084 - accuracy: 0.9681 - val_loss: 1.0798 - val_accuracy: 0.7701\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2072 - accuracy: 0.9700 - val_loss: 1.1120 - val_accuracy: 0.7738\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2044 - accuracy: 0.9697 - val_loss: 1.0856 - val_accuracy: 0.7752\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2084 - accuracy: 0.9675 - val_loss: 1.1093 - val_accuracy: 0.7713\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2060 - accuracy: 0.9690 - val_loss: 1.1410 - val_accuracy: 0.7684\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.2002 - accuracy: 0.9708 - val_loss: 1.1715 - val_accuracy: 0.7657\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.2028 - accuracy: 0.9698 - val_loss: 1.0801 - val_accuracy: 0.7780\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.1994 - accuracy: 0.9706 - val_loss: 1.0693 - val_accuracy: 0.7722\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1990 - accuracy: 0.9710 - val_loss: 1.1410 - val_accuracy: 0.7644\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1978 - accuracy: 0.9709 - val_loss: 1.1125 - val_accuracy: 0.7717\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1972 - accuracy: 0.9713 - val_loss: 1.1001 - val_accuracy: 0.7714\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1900 - accuracy: 0.9732 - val_loss: 1.1156 - val_accuracy: 0.7716\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1972 - accuracy: 0.9712 - val_loss: 1.1488 - val_accuracy: 0.7733\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.1932 - accuracy: 0.9725 - val_loss: 1.1049 - val_accuracy: 0.7758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d9b8b15b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

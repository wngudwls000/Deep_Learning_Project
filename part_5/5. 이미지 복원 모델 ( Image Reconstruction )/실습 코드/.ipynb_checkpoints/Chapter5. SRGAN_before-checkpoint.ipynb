{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRResnet-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, PReLU, LeakyReLU, Layer, Conv2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, channel=64, kernel_size=(3, 3)):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(channel, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.prelu = PReLU()\n",
    "        self.conv2 = Conv2D(channel, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        h = self.prelu(self.bn1(self.conv1(x), training))\n",
    "        return x + self.bn2(self.conv2(h), training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv-Bn-Relu Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnLReluBlock(Layer):\n",
    "    def __init__(self, channel=64, kernel_size=(3, 3)):\n",
    "        super().__init__()\n",
    "        self.conv = Conv2D(channel, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.lrelu = LeakyReLU()\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        return self.lrelu(self.bn(self.conv(x), training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator (SRResnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self, channel=64, num_resblock=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(channel, (9, 9), padding='same')\n",
    "        self.prelu1 = PReLU()\n",
    "        \n",
    "        self.resblock_list = [ResidualBlock(channel, (3, 3)) for _ in range(num_resblock)]\n",
    "        \n",
    "        self.conv2 = Conv2D(channel, (3, 3), padding='same', use_bias=False)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.prelu2 = PReLU()\n",
    "        \n",
    "        self.conv3 = Conv2D(channel * 4, (3, 3), padding='same')\n",
    "        self.prelu3 = PReLU()\n",
    "        \n",
    "        self.conv4 = Conv2D(channel * 4, (3, 3), padding='same')\n",
    "        self.prelu4 = PReLU()\n",
    "        self.conv5 = Conv2D(3, (9, 9), padding='same')\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        h = self.prelu1(self.conv1(x))\n",
    "        h_skip = h\n",
    "        \n",
    "        for resblock in self.resblock_list:\n",
    "            h = resblock(h, training)\n",
    "        \n",
    "        h = self.prelu2(self.bn(self.conv2(h), training))\n",
    "        h = h + h_skip\n",
    "        \n",
    "        h = self.prelu3(tf.nn.depth_to_space(self.conv3(h), 2))\n",
    "        h = self.prelu4(tf.nn.depth_to_space(self.conv4(h), 2))\n",
    "        return self.conv5(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self, channel=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(channel, (3, 3), padding='same')\n",
    "        self.lrelu1 = LeakyReLU()\n",
    "        \n",
    "        self.block_list = list()\n",
    "        self.block_list.append(ConvBnLReluBlock(channel))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 2))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 2))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 4))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 4))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 8))\n",
    "        self.block_list.append(ConvBnLReluBlock(channel * 8))\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(1024)\n",
    "        self.lrelu2 = LeakyReLU()\n",
    "        self.dense2 = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        h = self.lrelu1(self.conv1(x))\n",
    "        for block in self.block_list:\n",
    "            h = block(h, training)\n",
    "        h = self.flatten(h)\n",
    "        h = self.lrelu2(self.dense1(h))\n",
    "        return self.dense2(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (Caltech101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(name='caltech101', split='train')\n",
    "dataset = dataset.map(lambda x: (tf.image.resize(tf.cast(x['image'], tf.float32), (8, 8), tf.image.ResizeMethod.BICUBIC) / 255.0,\n",
    "                                 tf.image.resize(tf.cast(x['image'], tf.float32), (32, 32), tf.image.ResizeMethod.BICUBIC) / 255.0)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Model, Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(16)\n",
    "discriminator = Discriminator(16)\n",
    "\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "vgg = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "vgg.trainable = False\n",
    "\n",
    "w_gan = 1e-2\n",
    "w_vgg = 1e-5\n",
    "\n",
    "optim_d = tf.optimizers.Adam(1e-4)\n",
    "optim_g = tf.optimizers.Adam(1e-4)\n",
    "\n",
    "d_mean = tf.metrics.Mean()\n",
    "g_mean = tf.metrics.Mean()\n",
    "vgg_mean = tf.metrics.Mean()\n",
    "l1_mean = tf.metrics.Mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def l1_loss_func(y, y_):\n",
    "    return tf.reduce_mean(tf.abs(y - y_))\n",
    "\n",
    "@tf.function\n",
    "def vgg_loss_func(y, y_):\n",
    "    return tf.reduce_mean((vgg(y) - vgg(y_)) ** 2)\n",
    "\n",
    "@tf.function\n",
    "def discriminator_loss(real, fake):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real), real)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake), fake)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "@tf.function\n",
    "def generator_loss(fake):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake), fake)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image_lr, image_hr, optim_d, optim_g):\n",
    "    with tf.GradientTape() as tape_d, tf.GradientTape() as tape_g:\n",
    "        image_sr = generator(image_lr, training=True)\n",
    "        \n",
    "        d_real = discriminator(image_hr, training=True)\n",
    "        d_fake = discriminator(image_sr, training=True)\n",
    "        \n",
    "        d_loss = discriminator_loss(d_real, d_fake)\n",
    "        g_loss = generator_loss(d_fake)\n",
    "        \n",
    "        vgg_loss = vgg_loss_func(image_hr, image_sr)\n",
    "        l1_loss = l1_loss_func(image_hr, image_sr)\n",
    "        \n",
    "        loss = w_gan * g_loss + w_vgg * vgg_loss + l1_loss\n",
    "        \n",
    "        gradients_d = tape_d.gradient(d_loss, discriminator.trainable_weights)\n",
    "        gradients_g = tape_g.gradient(loss, generator.trainable_weights)\n",
    "    \n",
    "    optim_d.apply_gradients(zip(gradients_d, discriminator.trainable_weights))\n",
    "    optim_g.apply_gradients(zip(gradients_g, generator.trainable_weights))\n",
    "    return d_loss, g_loss, vgg_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    File \"<ipython-input-9-918e515138d5>\", line 6, in train_step  *\n        d_real = discriminator(image_hr, training=True)\n    File \"C:\\Users\\wndnw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ResourceExhaustedError: Exception encountered when calling layer \"discriminator_4\" (type Discriminator).\n    \n    in user code:\n    \n        File \"<ipython-input-5-bd3f306e7490>\", line 26, in call  *\n            h = self.lrelu2(self.dense1(h))\n        File \"C:\\Users\\wndnw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\wndnw\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 1920, in random_uniform\n            return tf.random.uniform(\n    \n        ResourceExhaustedError: OOM when allocating tensor with shape[131072,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]\n    \n    \n    Call arguments received by layer \"discriminator_4\" (type Discriminator):\n      • x=tf.Tensor(shape=(1, 32, 32, 3), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-a0ab7c20fb66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_hr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_hr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0md_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1127\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"<ipython-input-9-918e515138d5>\", line 6, in train_step  *\n        d_real = discriminator(image_hr, training=True)\n    File \"C:\\Users\\wndnw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ResourceExhaustedError: Exception encountered when calling layer \"discriminator_4\" (type Discriminator).\n    \n    in user code:\n    \n        File \"<ipython-input-5-bd3f306e7490>\", line 26, in call  *\n            h = self.lrelu2(self.dense1(h))\n        File \"C:\\Users\\wndnw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\wndnw\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 1920, in random_uniform\n            return tf.random.uniform(\n    \n        ResourceExhaustedError: OOM when allocating tensor with shape[131072,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]\n    \n    \n    Call arguments received by layer \"discriminator_4\" (type Discriminator):\n      • x=tf.Tensor(shape=(1, 32, 32, 3), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for img_lr, img_hr in dataset:\n",
    "        d_loss, g_loss, vgg_loss, l1_loss = train_step(img_lr, img_hr, optim_d, optim_g)\n",
    "\n",
    "        d_mean.update_state(d_loss)\n",
    "        g_mean.update_state(g_loss)\n",
    "        vgg_mean.update_state(vgg_loss)\n",
    "        l1_mean.update_state(l1_loss)\n",
    "\n",
    "    print('epoch: {}, d_loss: {}, g_loss: {}, vgg_loss: {}, l1_loss: {}'.format(epoch+1,\n",
    "                                                                d_mean.result(),\n",
    "                                                                g_mean.result(),\n",
    "                                                                vgg_mean.result(),\n",
    "                                                                l1_mean.result()))\n",
    "    img_sr_list = list()\n",
    "    img_lr_list = list()\n",
    "    img_hr_list = list()\n",
    "    for img_lr, img_hr in dataset.take(10):\n",
    "        img_sr = generator(img_lr)\n",
    "        \n",
    "        img_lr_list.append(tf.image.resize(img_lr[0], (32, 32),\n",
    "                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR))\n",
    "        img_sr_list.append(img_sr[0])\n",
    "        img_hr_list.append(img_hr[0])\n",
    "    \n",
    "    img_lr = np.concatenate(img_lr_list, axis=1)\n",
    "    img_sr = np.concatenate(img_sr_list, axis=1)\n",
    "    img_hr = np.concatenate(img_hr_list, axis=1)\n",
    "    img = np.concatenate([img_lr, img_sr, img_hr], axis=0)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    d_mean.reset_states()\n",
    "    g_mean.reset_states()\n",
    "    vgg_mean.reset_states()\n",
    "    l1_mean.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
